{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Parsing iteration</h3>\n",
    "This file implements parsing of pages. HTML pages are opened sequentially, article tags are highlighted through the BeautifulSoup library. Parsing is performed according to the manually selected location of information in the DOM. Each article becomes an object of the Article class. The received data is recorded in csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Article import Article\n",
    "from Utils import parse_text, parse_tags, parse_saves, parse_views, is_ads\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>A set of attributes for retrieving information from pages.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id\n",
    "DATA_ID = 'data-story-id'\n",
    "# title\n",
    "CLASS_TITLE = 'story__title-link'\n",
    "# author id\n",
    "DATA_AUTHOR_ID = 'data-author-id'\n",
    "# author name\n",
    "CLASS_AUTHOR = 'story__user-link user__nick'\n",
    "# author name\n",
    "DATA_AUTHOR_NAME = 'data-name'\n",
    "# comments count\n",
    "DATA_COMMENTS_COUNT = 'data-comments'\n",
    "# rating info\n",
    "DATA_RATING = 'data-rating'\n",
    "# meta rating info\n",
    "DATA_META_RATING = 'data-meta-rating'\n",
    "# time\n",
    "DATA_TIME = 'data-timestamp'\n",
    "# tag info\n",
    "CLASS_TAG = 'tags__tag'\n",
    "# tag name\n",
    "DATA_TAG = 'data-tag'\n",
    "# saves\n",
    "CLASS_SAVES = 'story__save'\n",
    "# saves info\n",
    "DATA_SAVES = 'aria-label'\n",
    "# views\n",
    "CLASS_VIEWS = 'story__views-count'\n",
    "# views info\n",
    "DATA_VIEWS = 'aria-label'\n",
    "# text\n",
    "CLASS_TEXT = 'story-block_type_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_story(story, atr):\n",
    "    text = parse_text(story.find_all('div', class_=CLASS_TEXT))\n",
    "    tags = parse_tags(story.find_all('a', class_=CLASS_TAG), DATA_TAG)\n",
    "\n",
    "    saves = parse_saves(story.find(class_=CLASS_SAVES).attrs[DATA_SAVES])\n",
    "\n",
    "    views_info = story.find(class_=CLASS_VIEWS)\n",
    "    if views_info is None or views_info.get(CLASS_VIEWS) is None:\n",
    "        views = 0\n",
    "    else:\n",
    "        views = parse_views(views_info.get(CLASS_VIEWS), DATA_AUTHOR_ID)\n",
    "\n",
    "\n",
    "    if atr.get(DATA_RATING) is None:\n",
    "        rating = 0\n",
    "    else:\n",
    "        rating = atr[DATA_RATING]\n",
    "\n",
    "    article = Article(\n",
    "        atr[DATA_ID], \n",
    "        story.find(class_=CLASS_TITLE).text, \n",
    "        atr[DATA_AUTHOR_ID],\n",
    "        story.find(class_=CLASS_AUTHOR).attrs[DATA_AUTHOR_NAME],\n",
    "        atr[DATA_COMMENTS_COUNT],\n",
    "        rating,\n",
    "        atr[DATA_META_RATING],\n",
    "        atr[DATA_TIME],\n",
    "        tags,\n",
    "        views,\n",
    "        saves,\n",
    "        text)\n",
    "\n",
    "    return article.get_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'pages'\n",
    "files = os.listdir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_csv():\n",
    "    with open('result.csv', 'w') as csvfile:\n",
    "        fieldnames = ['id', 'title', 'author_id', 'author_name', 'comments', 'rating', 'rating_full', 'data', 'tags', 'views', 'saves', 'text']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for file in tqdm(files):\n",
    "            with open(os.path.join(dir_name, file), 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                soup = BeautifulSoup(content, 'lxml')\n",
    "                stories = soup.find_all('article', class_='story')\n",
    "\n",
    "                for story in stories:\n",
    "                    atr = story.attrs\n",
    "                    if is_ads(atr, DATA_AUTHOR_ID):\n",
    "                        continue\n",
    "                    else:\n",
    "                        writer.writerow(parse_story(story, atr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Launches data_to_csv</h3>\n",
    "<ul>\n",
    "<li>60 495 files, last is 3186, time: 2:07:00</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "name": "python386jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}