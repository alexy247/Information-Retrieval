{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Parsing iteration</h3>\n",
    "This file implements parsing of pages. HTML pages are opened sequentially, article tags are highlighted through the BeautifulSoup library. Parsing is performed according to the manually selected location of information in the DOM. Each article becomes an object of the Article class. The received data is recorded in csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Article import Article\n",
    "from Utils import parse_text, parse_tags, parse_saves, parse_views, is_ads\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>A set of attributes for retrieving information from pages.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id\n",
    "DATA_ID = 'data-story-id'\n",
    "# title\n",
    "CLASS_TITLE = 'story__title-link'\n",
    "# author id\n",
    "DATA_AUTHOR_ID = 'data-author-id'\n",
    "# author name\n",
    "CLASS_AUTHOR = 'story__user-link user__nick'\n",
    "# author name\n",
    "DATA_AUTHOR_NAME = 'data-name'\n",
    "# comments count\n",
    "DATA_COMMENTS_COUNT = 'data-comments'\n",
    "# rating info\n",
    "DATA_RATING = 'data-rating'\n",
    "# meta rating info\n",
    "DATA_META_RATING = 'data-meta-rating'\n",
    "# time class\n",
    "CLASS_DATE = 'story__datetime'\n",
    "# time atr\n",
    "DATE_ATR = 'datetime'\n",
    "# tag info\n",
    "CLASS_TAG = 'tags__tag'\n",
    "# tag name\n",
    "DATA_TAG = 'data-tag'\n",
    "# saves\n",
    "CLASS_SAVES = 'story__save'\n",
    "# saves info\n",
    "DATA_SAVES = 'aria-label'\n",
    "# views\n",
    "CLASS_VIEWS = 'story__views-count'\n",
    "# views info\n",
    "DATA_VIEWS = 'aria-label'\n",
    "# text\n",
    "CLASS_TEXT = 'story-block_type_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_story(story, atr):\n",
    "    text = parse_text(story.find_all('div', class_=CLASS_TEXT))\n",
    "    tags = parse_tags(story.find_all('a', class_=CLASS_TAG), DATA_TAG)\n",
    "    date = story.find('time', class_=CLASS_DATE).attrs[DATE_ATR]\n",
    "\n",
    "    saves = parse_saves(story.find(class_=CLASS_SAVES).attrs[DATA_SAVES])\n",
    "\n",
    "    views_info = story.find(class_=CLASS_VIEWS)\n",
    "    if views_info is None or views_info.get(CLASS_VIEWS) is None:\n",
    "        views = 0\n",
    "    else:\n",
    "        views = parse_views(views_info.get(CLASS_VIEWS), DATA_AUTHOR_ID)\n",
    "\n",
    "\n",
    "    if atr.get(DATA_RATING) is None:\n",
    "        rating = 0\n",
    "    else:\n",
    "        rating = atr[DATA_RATING]\n",
    "\n",
    "    article = Article(\n",
    "        atr[DATA_ID], \n",
    "        story.find(class_=CLASS_TITLE).text, \n",
    "        atr[DATA_AUTHOR_ID],\n",
    "        story.find(class_=CLASS_AUTHOR).attrs[DATA_AUTHOR_NAME],\n",
    "        atr[DATA_COMMENTS_COUNT],\n",
    "        rating,\n",
    "        atr[DATA_META_RATING],\n",
    "        date,\n",
    "        tags,\n",
    "        views,\n",
    "        saves,\n",
    "        text)\n",
    "\n",
    "    return article.get_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'pages'\n",
    "files = os.listdir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_csv():\n",
    "    with open('result.csv', 'w') as csvfile:\n",
    "        fieldnames = ['id', 'title', 'author_id', 'author_name', 'comments', 'rating', 'rating_full', 'date', 'tags', 'views', 'saves', 'text']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for file in tqdm(files):\n",
    "            with open(os.path.join(dir_name, file), 'r', encoding='utf-8') as f:\n",
    "                if not file.startswith('.'):\n",
    "                    content = f.read()\n",
    "                    soup = BeautifulSoup(content, 'lxml')\n",
    "                    stories = soup.find_all('article', class_='story')\n",
    "\n",
    "                    for story in stories:\n",
    "                        atr = story.attrs\n",
    "                        if is_ads(atr, DATA_AUTHOR_ID) or story.find(class_='story__sponsor') is not None:\n",
    "                            continue\n",
    "                        else:\n",
    "                            writer.writerow(parse_story(story, atr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Launches data_to_csv</h3>\n",
    "<ul>\n",
    "<li>120 531 files, last is 3186, time: 2:07:00</li>\n",
    "<li>120 531 files, last is 3186, time: 2:25:52 (after fixed time parsing, added check for hidden files)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120531/120531 [2:25:52<00:00, 13.77it/s]\n"
     ]
    }
   ],
   "source": [
    "data_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = 3186\n",
    "END_DATE = 3359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_to_csv():\n",
    "    with open('result.csv', 'a') as csvfile:\n",
    "        fieldnames = ['id', 'title', 'author_id', 'author_name', 'comments', 'rating', 'rating_full', 'date', 'tags', 'views', 'saves', 'text']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        for date in tqdm(range(START_DATE, END_DATE)):\n",
    "            for page in range(1,112):\n",
    "                file_name = str(date) + \"-\" + str(page) + \".html\"\n",
    "                try:\n",
    "                    with open(os.path.join(dir_name, file_name), 'r', encoding='utf-8') as f:\n",
    "                        content = f.read()\n",
    "                        soup = BeautifulSoup(content, 'lxml')\n",
    "                        stories = soup.find_all('article', class_='story')\n",
    "\n",
    "                        for story in stories:\n",
    "                            atr = story.attrs\n",
    "                            if is_ads(atr, DATA_AUTHOR_ID) or story.find(class_='story__sponsor') is not None:\n",
    "                                continue\n",
    "                            else:\n",
    "                                writer.writerow(parse_story(story, atr))                \n",
    "                except:\n",
    "                    print('error in file ' + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Launches add_data_to_csv</h3>\n",
    "<ul>\n",
    "<li>0:23:42, from 3186 to 3359, error in file 3349-53.html</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 163/173 [21:42<02:17, 13.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in file 3349-53.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [23:42<00:00,  8.22s/it]\n"
     ]
    }
   ],
   "source": [
    "add_data_to_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('python@3.8')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}